"""
ETF ìˆ˜ìµë¥  ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ (GitHub Actions ìµœì í™”)
- ìš´ìš©ê¸ˆì•¡ ìƒìœ„ 100ê°œ ETF ì¤‘ 1ë…„ ìˆ˜ìµë¥  ê¸°ì¤€ ìƒìœ„/í•˜ìœ„ 50ê°œ ë¶„ì„
- 10ê°œ ê¸°ê°„ë³„ ìˆ˜ìµë¥  ë° ìˆœìœ„ ê³„ì‚°
- ìë™ ë¶„ë¥˜: ì„¹í„°, êµ­ë‚´ì™¸, ë ˆë²„ë¦¬ì§€, í™˜í—¤ì§€, ë°°ë‹¹ìœ í˜•
- ë°ì´í„° ì €ì¥: JSON, Excel, Markdown â†’ Git push â†’ Telegram ìš”ì•½ ì „ì†¡
"""

import pandas as pd
import numpy as np
from pykrx import stock
from datetime import datetime, timedelta
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
import requests
from typing import Dict, Tuple, List
import warnings
import os
import json
warnings.filterwarnings('ignore')


class ETFPerformanceAnalyzer:
    """ETF ìˆ˜ìµë¥  ë¶„ì„ê¸° (GitHub Actions í˜¸í™˜)"""
    
    def __init__(self, telegram_token: str = None, chat_id: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            telegram_token: í…”ë ˆê·¸ë¨ ë´‡ í† í° (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ ê°€ëŠ¥)
            chat_id: í…”ë ˆê·¸ë¨ ì±„íŒ…ë°© ID (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ ê°€ëŠ¥)
        """
        self.telegram_token = telegram_token or os.getenv('TELEGRAM_TOKEN')
        self.chat_id = chat_id or os.getenv('CHAT_ID')
        self.base_date = None
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('market_data', exist_ok=True)
        os.makedirs('analysis_reports', exist_ok=True)
    
    def get_last_trading_day(self) -> str:
        """ë§ˆì§€ë§‰ ì˜ì—…ì¼ ê°€ì ¸ì˜¤ê¸° (ì „ì¼ ë§ˆê° ê¸°ì¤€)"""
        today = datetime.now()
        
        # ì›”ìš”ì¼/ì¼ìš”ì¼ì€ ì‘ì—… ì•ˆí•¨
        if today.weekday() in [0, 6]:
            return None
        
        if today.weekday() == 0:  # ì›”ìš”ì¼
            last_day = today - timedelta(days=3)
        elif today.weekday() == 6:  # ì¼ìš”ì¼
            last_day = today - timedelta(days=2)
        else:
            last_day = today - timedelta(days=1)
        
        date_str = last_day.strftime('%Y%m%d')
        try:
            test = stock.get_index_ohlcv(date_str, date_str, "1001")
            if len(test) == 0:
                return self.get_previous_trading_day(last_day)
            return date_str
        except:
            return self.get_previous_trading_day(last_day)
    
    def get_previous_trading_day(self, from_date: datetime) -> str:
        """ì´ì „ ì˜ì—…ì¼ ì°¾ê¸°"""
        for i in range(1, 10):
            test_date = from_date - timedelta(days=i)
            date_str = test_date.strftime('%Y%m%d')
            try:
                test = stock.get_index_ohlcv(date_str, date_str, "1001")
                if len(test) > 0:
                    return date_str
            except:
                continue
        return (datetime.now() - timedelta(days=5)).strftime('%Y%m%d')
    
    def get_date_before_period(self, base_date: str, days: int) -> str:
        """íŠ¹ì • ê¸°ê°„ ì „ ë‚ ì§œ ê³„ì‚°"""
        base = datetime.strptime(base_date, '%Y%m%d')
        target = base - timedelta(days=days)
        return target.strftime('%Y%m%d')
    
    def classify_etf(self, name: str, code: str) -> Dict[str, str]:
        """
        ETF íŠ¹ì„± ìë™ ë¶„ë¥˜
        
        ë¶„ë¥˜ í•­ëª©:
        - ETFì„¹í„°: ë°˜ë„ì²´, IT/í…Œí¬, 2ì°¨ì „ì§€, ë°”ì´ì˜¤, ê¸ˆìœµ, ì—ë„ˆì§€, ë¶€ë™ì‚°, ì±„ê¶Œ, ì›ìì¬, ìë™ì°¨, ì¢…í•©ì§€ìˆ˜, ê¸°íƒ€
        - êµ­ë‚´ì™¸êµ¬ë¶„: êµ­ë‚´, í•´ì™¸
        - ë ˆë²„ë¦¬ì§€: ì—†ìŒ, 2ë°°, 3ë°°, ì¸ë²„ìŠ¤
        - í™˜í—¤ì§€: í•´ë‹¹ì—†ìŒ(êµ­ë‚´), í™˜í—¤ì§€, í™˜ë…¸ì¶œ
        - ë°°ë‹¹ìœ í˜•: ì¼ë°˜, ë°°ë‹¹í˜•, ì„±ì¥í˜•
        """
        classification = {
            'êµ­ë‚´ì™¸êµ¬ë¶„': 'êµ­ë‚´',
            'ë ˆë²„ë¦¬ì§€': 'ì—†ìŒ',
            'í™˜í—¤ì§€': 'í•´ë‹¹ì—†ìŒ',
            'ë°°ë‹¹ìœ í˜•': 'ì¼ë°˜',
            'ETFì„¹í„°': 'ê¸°íƒ€'
        }
        
        # êµ­ë‚´/í•´ì™¸ êµ¬ë¶„
        overseas_keywords = ['ë¯¸êµ­', 'S&P', 'NASDAQ', 'SPY', 'ë‚˜ìŠ¤ë‹¥', 'ì¤‘êµ­', 'ì¼ë³¸', 
                            'ìœ ëŸ½', 'ê¸€ë¡œë²Œ', 'MSCI', 'ì„ ì§„êµ­', 'ì´ë¨¸ì§•', 'ë² íŠ¸ë‚¨', 
                            'ì¸ë„', 'USA', 'China', 'Japan', 'Europe']
        if any(keyword in name for keyword in overseas_keywords):
            classification['êµ­ë‚´ì™¸êµ¬ë¶„'] = 'í•´ì™¸'
        
        # ë ˆë²„ë¦¬ì§€ êµ¬ë¶„
        if 'LEVERAGE' in name or 'ë ˆë²„ë¦¬ì§€' in name:
            if '2X' in name or '2ë°°' in name:
                classification['ë ˆë²„ë¦¬ì§€'] = '2ë°°'
            elif '3X' in name or '3ë°°' in name:
                classification['ë ˆë²„ë¦¬ì§€'] = '3ë°°'
            else:
                classification['ë ˆë²„ë¦¬ì§€'] = '2ë°°'
        elif 'INVERSE' in name or 'ì¸ë²„ìŠ¤' in name or 'ê³±ë²„ìŠ¤' in name or 'Short' in name:
            classification['ë ˆë²„ë¦¬ì§€'] = 'ì¸ë²„ìŠ¤'
        
        # í™˜í—¤ì§€ êµ¬ë¶„ (í•´ì™¸ ETFë§Œ)
        if classification['êµ­ë‚´ì™¸êµ¬ë¶„'] == 'í•´ì™¸':
            if 'í™˜í—¤ì§€' in name or '(H)' in name or 'Hedged' in name:
                classification['í™˜í—¤ì§€'] = 'í™˜í—¤ì§€'
            else:
                classification['í™˜í—¤ì§€'] = 'í™˜ë…¸ì¶œ'
        
        # ë°°ë‹¹ ìœ í˜•
        if 'ë°°ë‹¹' in name or 'DIV' in name or 'Dividend' in name or 'ê³ ë°°ë‹¹' in name:
            classification['ë°°ë‹¹ìœ í˜•'] = 'ë°°ë‹¹í˜•'
        elif 'ì„±ì¥' in name or 'Growth' in name:
            classification['ë°°ë‹¹ìœ í˜•'] = 'ì„±ì¥í˜•'
        
        # ETF ì„¹í„° ë¶„ë¥˜
        sector_keywords = {
            'ë°˜ë„ì²´': ['ë°˜ë„ì²´', 'ì¹©', 'Chip', 'Semi', 'í•„ë¼ë¸í”¼ì•„', 'SOX'],
            'IT/í…Œí¬': ['IT', 'ì¸í„°ë„·', 'í…Œí¬', 'Tech', 'Technology', 'Internet', 
                      'ì†Œí”„íŠ¸ì›¨ì–´', 'Cloud', 'Cyber', 'Software'],
            '2ì°¨ì „ì§€': ['2ì°¨ì „ì§€', 'ë°°í„°ë¦¬', 'Battery', 'ì „ê¸°ì°¨'],
            'ë°”ì´ì˜¤': ['ë°”ì´ì˜¤', 'Bio', 'ì œì•½', 'Pharma', 'í—¬ìŠ¤ì¼€ì–´', 'Healthcare', 'Health'],
            'ê¸ˆìœµ': ['ê¸ˆìœµ', 'ì€í–‰', 'Bank', 'Finance', 'Financial'],
            'ì—ë„ˆì§€': ['ì—ë„ˆì§€', 'Energy', 'ì›ìœ ', 'Oil', 'Gas'],
            'ë¶€ë™ì‚°': ['ë¦¬ì¸ ', 'REIT', 'ë¶€ë™ì‚°', 'Real Estate'],
            'ì±„ê¶Œ': ['ì±„ê¶Œ', 'Bond', 'êµ­ì±„', 'íšŒì‚¬ì±„', 'Treasury', 'TLT'],
            'ì›ìì¬': ['ê¸ˆ', 'Gold', 'ì€', 'Silver', 'ì›ìì¬', 'Commodity'],
            'ìë™ì°¨': ['ìë™ì°¨', 'Auto', 'Car', 'Mobility', 'Vehicle'],
            'ì¢…í•©ì§€ìˆ˜': ['KOSPI', 'KOSDAQ', 'KRX', 'S&P500', 'NASDAQ100', 'Russell', 'Dow', 'QQQ']
        }
        
        for sector, keywords in sector_keywords.items():
            if any(keyword in name for keyword in keywords):
                classification['ETFì„¹í„°'] = sector
                break
        
        return classification
    
    def get_all_etf_list(self) -> pd.DataFrame:
        """ì „ì²´ ETF ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            date_str = self.base_date
            etf_list = stock.get_etf_ticker_list(date_str)
            
            etf_data = []
            for ticker in etf_list:
                try:
                    name = stock.get_etf_ticker_name(ticker)
                    ohlcv = stock.get_etf_ohlcv_by_date(date_str, date_str, ticker)
                    
                    if len(ohlcv) > 0:
                        etf_data.append({
                            'ì¢…ëª©ì½”ë“œ': ticker,
                            'ì¢…ëª©ëª…': name,
                            'í˜„ì¬ê°€': ohlcv['ì¢…ê°€'].values[0]
                        })
                except:
                    continue
            
            return pd.DataFrame(etf_data)
            
        except Exception as e:
            print(f"Error in get_all_etf_list: {e}")
            return pd.DataFrame()
    
    def calculate_returns(self, ticker: str, base_date: str) -> Dict[str, float]:
        """
        ê¸°ê°„ë³„ ìˆ˜ìµë¥  ê³„ì‚°
        
        ê³„ì‚° ê¸°ê°„: 1ì¼, 3ì¼, 1ì£¼, 2ì£¼, 1ê°œì›”, 3ê°œì›”, 6ê°œì›”, 12ê°œì›”, 3ë…„, 5ë…„
        ìˆ˜ìµë¥  = (í˜„ì¬ê°€ - ê³¼ê±°ê°€) / ê³¼ê±°ê°€ * 100
        """
        returns = {}
        periods = {
            '1ì¼': 1, '3ì¼': 3, '1ì£¼': 7, '2ì£¼': 14, '1ê°œì›”': 30,
            '3ê°œì›”': 90, '6ê°œì›”': 180, '12ê°œì›”': 365, '3ë…„': 365*3, '5ë…„': 365*5
        }
        
        try:
            start_date = self.get_date_before_period(base_date, 365 * 6)
            df = stock.get_etf_ohlcv_by_date(start_date, base_date, ticker)
            
            if len(df) == 0:
                return {period: 'ë¯¸ì¶œì‹œ' for period in periods.keys()}
            
            listing_date = df.index[0]
            base_dt = pd.to_datetime(base_date)
            
            for period_name, days in periods.items():
                try:
                    target_date = base_dt - pd.Timedelta(days=days)
                    
                    if target_date < listing_date:
                        returns[period_name] = 'ë¯¸ì¶œì‹œ'
                        continue
                    
                    base_price = df.loc[base_date, 'ì¢…ê°€']
                    available_dates = df.index[df.index <= target_date]
                    
                    if len(available_dates) == 0:
                        returns[period_name] = 'ë¯¸ì¶œì‹œ'
                        continue
                    
                    target_actual_date = available_dates[-1]
                    target_price = df.loc[target_actual_date, 'ì¢…ê°€']
                    
                    ret = ((base_price - target_price) / target_price) * 100
                    returns[period_name] = round(ret, 2)
                    
                except:
                    returns[period_name] = 'ë¯¸ì¶œì‹œ'
                    
        except:
            returns = {period: 'ë¯¸ì¶œì‹œ' for period in periods.keys()}
        
        return returns
    
    def get_etf_nav(self, ticker: str, date: str) -> float:
        """
        ETF ìš´ìš©ê¸ˆì•¡ ì¶”ì •
        
        ê³„ì‚° ë°©ì‹: ì¢…ê°€ Ã— ê±°ë˜ëŸ‰ / 100,000 (ì–µì› ë‹¨ìœ„)
        ì‹¤ì œ ìˆœìì‚°ì€ ì•„ë‹ˆì§€ë§Œ ê±°ë˜ê·œëª¨ì˜ proxyë¡œ ì‚¬ìš©
        """
        try:
            ohlcv = stock.get_etf_ohlcv_by_date(date, date, ticker)
            if len(ohlcv) > 0:
                price = ohlcv['ì¢…ê°€'].values[0]
                volume = ohlcv['ê±°ë˜ëŸ‰'].values[0]
                market_cap = price * volume / 100000
                return market_cap
            return 0
        except:
            return 0
    
    def analyze_etfs(self) -> pd.DataFrame:
        """
        ì „ì²´ ETF ë¶„ì„ ìˆ˜í–‰
        
        í”„ë¡œì„¸ìŠ¤:
        1. ë§ˆì§€ë§‰ ì˜ì—…ì¼ í™•ì¸
        2. ì „ì²´ ETF ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        3. ìš´ìš©ê¸ˆì•¡ ê¸°ì¤€ ìƒìœ„ 100ê°œ ì„ ë³„
        4. ê° ETFë³„ 10ê°œ ê¸°ê°„ ìˆ˜ìµë¥  ê³„ì‚°
        5. ê° ê¸°ê°„ë³„ ìˆœìœ„ ê³„ì‚°
        6. 1ë…„ ìˆ˜ìµë¥  ê¸°ì¤€ ìƒìœ„/í•˜ìœ„ 50ê°œ êµ¬ë¶„
        """
        print("=" * 60)
        print("ETF ìˆ˜ìµë¥  ë¶„ì„ ì‹œì‘")
        print("=" * 60)
        
        self.base_date = self.get_last_trading_day()
        
        if self.base_date is None:
            print("âš ï¸  ì˜¤ëŠ˜ì€ ë¶„ì„ ì‘ì—…ì¼ì´ ì•„ë‹™ë‹ˆë‹¤ (ì›”ìš”ì¼/ì¼ìš”ì¼)")
            return None
        
        print(f"\nğŸ“… ê¸°ì¤€ì¼: {self.base_date}")
        
        print("\n1ë‹¨ê³„: ETF ëª©ë¡ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        etf_list = self.get_all_etf_list()
        print(f"   âœ“ ì´ {len(etf_list)}ê°œ ETF ë°œê²¬")
        
        print("\n2ë‹¨ê³„: ìš´ìš©ê¸ˆì•¡ ê³„ì‚° ë° ì •ë ¬ ì¤‘...")
        etf_list['ìš´ìš©ê¸ˆì•¡_ì–µ'] = etf_list['ì¢…ëª©ì½”ë“œ'].apply(
            lambda x: self.get_etf_nav(x, self.base_date)
        )
        etf_list = etf_list.sort_values('ìš´ìš©ê¸ˆì•¡_ì–µ', ascending=False)
        etf_list['ìš´ìš©ê¸ˆì•¡ìˆœìœ„'] = range(1, len(etf_list) + 1)
        etf_list = etf_list.head(100).copy()
        print(f"   âœ“ ìƒìœ„ 100ê°œ ETF ì„ ë³„ ì™„ë£Œ")
        
        print("\n3ë‹¨ê³„: ìˆ˜ìµë¥  ê³„ì‚° ì¤‘ (5-10ë¶„ ì†Œìš”)...")
        all_results = []
        
        for idx, (i, row) in enumerate(etf_list.iterrows(), 1):
            ticker = row['ì¢…ëª©ì½”ë“œ']
            name = row['ì¢…ëª©ëª…']
            
            if idx % 10 == 0:
                print(f"   ì§„í–‰ë¥ : {idx}/100 ({idx}%)")
            
            returns = self.calculate_returns(ticker, self.base_date)
            classification = self.classify_etf(name, ticker)
            
            result = {
                'ì¢…ëª©ëª…': name,
                'ì¢…ëª©ì½”ë“œ': ticker,
                'ìš´ìš©ê¸ˆì•¡ìˆœìœ„': row['ìš´ìš©ê¸ˆì•¡ìˆœìœ„'],
                'ìš´ìš©ê¸ˆì•¡_ì–µ': round(row['ìš´ìš©ê¸ˆì•¡_ì–µ'], 0),
                **classification,
            }
            
            for period in ['1ì¼', '3ì¼', '1ì£¼', '2ì£¼', '1ê°œì›”', '3ê°œì›”', 
                          '6ê°œì›”', '12ê°œì›”', '3ë…„', '5ë…„']:
                result[f'{period}_ìˆ˜ìµë¥ '] = returns[period]
            
            all_results.append(result)
        
        df = pd.DataFrame(all_results)
        
        print("\n4ë‹¨ê³„: ìˆœìœ„ ê³„ì‚° ì¤‘...")
        for period in ['1ì¼', '3ì¼', '1ì£¼', '2ì£¼', '1ê°œì›”', '3ê°œì›”', 
                      '6ê°œì›”', '12ê°œì›”', '3ë…„', '5ë…„']:
            col = f'{period}_ìˆ˜ìµë¥ '
            rank_col = f'{period}_ìˆœìœ„'
            
            valid_mask = df[col] != 'ë¯¸ì¶œì‹œ'
            df.loc[valid_mask, rank_col] = df.loc[valid_mask, col].rank(
                ascending=False, method='min').astype(int)
            df.loc[~valid_mask, rank_col] = 'ë¯¸ì¶œì‹œ'
        
        print("\n5ë‹¨ê³„: ìƒìœ„/í•˜ìœ„ 50ê°œ êµ¬ë¶„ ì¤‘...")
        valid_12month = df['12ê°œì›”_ìˆ˜ìµë¥ '] != 'ë¯¸ì¶œì‹œ'
        df_valid = df[valid_12month].copy()
        df_invalid = df[~valid_12month].copy()
        
        df_valid = df_valid.sort_values('12ê°œì›”_ìˆ˜ìµë¥ ', ascending=False)
        
        top_50 = df_valid.head(50).copy()
        top_50['êµ¬ë¶„'] = 'ìƒìœ„ 50ê°œ'
        
        bottom_50 = df_valid.tail(50).copy()
        bottom_50['êµ¬ë¶„'] = 'í•˜ìœ„ 50ê°œ'
        
        df_invalid['êµ¬ë¶„'] = 'ë¯¸ì¶œì‹œ(1ë…„)'
        
        final_df = pd.concat([top_50, bottom_50, df_invalid], ignore_index=True)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        column_order = ['ì¢…ëª©ëª…', 'ì¢…ëª©ì½”ë“œ', 'ìš´ìš©ê¸ˆì•¡ìˆœìœ„', 'ìš´ìš©ê¸ˆì•¡_ì–µ',
                       'ETFì„¹í„°', 'êµ­ë‚´ì™¸êµ¬ë¶„', 'ë ˆë²„ë¦¬ì§€', 'í™˜í—¤ì§€', 'ë°°ë‹¹ìœ í˜•', 'êµ¬ë¶„']
        
        for period in ['1ì¼', '3ì¼', '1ì£¼', '2ì£¼', '1ê°œì›”', '3ê°œì›”', 
                      '6ê°œì›”', '12ê°œì›”', '3ë…„', '5ë…„']:
            column_order.extend([f'{period}_ìˆœìœ„', f'{period}_ìˆ˜ìµë¥ '])
        
        final_df = final_df[column_order]
        
        print("   âœ“ ë¶„ì„ ì™„ë£Œ!")
        return final_df
    
    def save_to_json(self, df: pd.DataFrame) -> str:
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        filename = f"market_data/etf_performance_{self.base_date}.json"
        
        # DataFrameì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (NaN ì²˜ë¦¬)
        data = {
            'analysis_date': self.base_date,
            'total_etfs': len(df),
            'etf_data': df.to_dict('records')
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"   âœ“ JSON ì €ì¥: {filename}")
        return filename
    
    def save_to_excel(self, df: pd.DataFrame) -> str:
        """
        ì—‘ì…€ íŒŒì¼ ìƒì„±
        
        ìŠ¤íƒ€ì¼:
        - í—¤ë”: íŒŒë€ìƒ‰ ë°°ê²½, í°ìƒ‰ ê¸€ì, ê°€ìš´ë° ì •ë ¬
        - ë°ì´í„°: í…Œë‘ë¦¬, ìë™ ì»¬ëŸ¼ ë„ˆë¹„
        """
        filename = f"analysis_reports/etf_performance_{self.base_date}.xlsx"
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='ETF ìˆ˜ìµë¥  ë¶„ì„', index=False)
            
            workbook = writer.book
            worksheet = writer.sheets['ETF ìˆ˜ìµë¥  ë¶„ì„']
            
            # í—¤ë” ìŠ¤íƒ€ì¼
            header_fill = PatternFill(start_color='366092', end_color='366092', 
                                     fill_type='solid')
            header_font = Font(bold=True, color='FFFFFF', size=11)
            
            for cell in worksheet[1]:
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ì»¬ëŸ¼ ë„ˆë¹„
            worksheet.column_dimensions['A'].width = 35  # ì¢…ëª©ëª…
            worksheet.column_dimensions['B'].width = 12  # ì¢…ëª©ì½”ë“œ
            worksheet.column_dimensions['C'].width = 15  # ìš´ìš©ê¸ˆì•¡ìˆœìœ„
            worksheet.column_dimensions['D'].width = 15  # ìš´ìš©ê¸ˆì•¡
            worksheet.column_dimensions['E'].width = 15  # ETFì„¹í„°
            worksheet.column_dimensions['F'].width = 12  # êµ­ë‚´ì™¸êµ¬ë¶„
            worksheet.column_dimensions['G'].width = 12  # ë ˆë²„ë¦¬ì§€
            worksheet.column_dimensions['H'].width = 12  # í™˜í—¤ì§€
            worksheet.column_dimensions['I'].width = 12  # ë°°ë‹¹ìœ í˜•
            worksheet.column_dimensions['J'].width = 15  # êµ¬ë¶„
            
            for col in list(worksheet.columns)[10:]:
                worksheet.column_dimensions[col[0].column_letter].width = 12
        
        print(f"   âœ“ Excel ì €ì¥: {filename}")
        return filename
    
    def save_to_markdown(self, df: pd.DataFrame) -> str:
        """ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        filename = f"analysis_reports/etf_performance_{self.base_date}.md"
        
        # 1ë…„ ê¸°ì¤€ ì •ë ¬
        df_1y = df[df['12ê°œì›”_ìˆ˜ìµë¥ '] != 'ë¯¸ì¶œì‹œ'].copy()
        df_1y = df_1y.sort_values('12ê°œì›”_ìˆ˜ìµë¥ ', ascending=False)
        
        # 1ì£¼ì¼ ê¸°ì¤€ ì •ë ¬
        df_1w = df[df['1ì£¼_ìˆ˜ìµë¥ '] != 'ë¯¸ì¶œì‹œ'].copy()
        df_1w = df_1w.sort_values('1ì£¼_ìˆ˜ìµë¥ ', ascending=False)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# ETF ìˆ˜ìµë¥  ë¶„ì„ ë³´ê³ ì„œ\n\n")
            f.write(f"**ë¶„ì„ ê¸°ì¤€ì¼**: {self.base_date}\n\n")
            f.write(f"**ë¶„ì„ ëŒ€ìƒ**: {len(df)}ê°œ ETF (ìš´ìš©ê¸ˆì•¡ ìƒìœ„ 100ê°œ)\n\n")
            f.write("---\n\n")
            
            # 1ë…„ ê¸°ì¤€ TOP 10
            f.write("## ğŸ“ˆ 1ë…„ ìˆ˜ìµë¥  ê¸°ì¤€\n\n")
            f.write("### ğŸ” ìƒìœ„ 10ê°œ\n\n")
            f.write("| ìˆœìœ„ | ì¢…ëª©ëª… | ì¢…ëª©ì½”ë“œ | 1ë…„ ìˆ˜ìµë¥  | 1ì£¼ ìˆ˜ìµë¥  | ETFì„¹í„° | êµ­ë‚´ì™¸ |\n")
            f.write("|------|--------|----------|-----------|-----------|---------|--------|\n")
            
            for idx, row in df_1y.head(10).iterrows():
                f.write(f"| {int(row['12ê°œì›”_ìˆœìœ„'])} | {row['ì¢…ëª©ëª…']} | {row['ì¢…ëª©ì½”ë“œ']} | "
                       f"{row['12ê°œì›”_ìˆ˜ìµë¥ ']}% | {row['1ì£¼_ìˆ˜ìµë¥ ']}% | "
                       f"{row['ETFì„¹í„°']} | {row['êµ­ë‚´ì™¸êµ¬ë¶„']} |\n")
            
            f.write("\n### ğŸ”» í•˜ìœ„ 10ê°œ\n\n")
            f.write("| ìˆœìœ„ | ì¢…ëª©ëª… | ì¢…ëª©ì½”ë“œ | 1ë…„ ìˆ˜ìµë¥  | 1ì£¼ ìˆ˜ìµë¥  | ETFì„¹í„° | êµ­ë‚´ì™¸ |\n")
            f.write("|------|--------|----------|-----------|-----------|---------|--------|\n")
            
            for idx, row in df_1y.tail(10).iterrows():
                f.write(f"| {int(row['12ê°œì›”_ìˆœìœ„'])} | {row['ì¢…ëª©ëª…']} | {row['ì¢…ëª©ì½”ë“œ']} | "
                       f"{row['12ê°œì›”_ìˆ˜ìµë¥ ']}% | {row['1ì£¼_ìˆ˜ìµë¥ ']}% | "
                       f"{row['ETFì„¹í„°']} | {row['êµ­ë‚´ì™¸êµ¬ë¶„']} |\n")
            
            # 1ì£¼ì¼ ê¸°ì¤€ TOP 10
            f.write("\n---\n\n")
            f.write("## ğŸ“Š 1ì£¼ì¼ ìˆ˜ìµë¥  ê¸°ì¤€\n\n")
            f.write("### ğŸ” ìƒìœ„ 10ê°œ\n\n")
            f.write("| ìˆœìœ„ | ì¢…ëª©ëª… | ì¢…ëª©ì½”ë“œ | 1ì£¼ ìˆ˜ìµë¥  | 1ë…„ ìˆ˜ìµë¥  | ETFì„¹í„° | êµ­ë‚´ì™¸ |\n")
            f.write("|------|--------|----------|-----------|-----------|---------|--------|\n")
            
            for idx, row in df_1w.head(10).iterrows():
                f.write(f"| {int(row['1ì£¼_ìˆœìœ„'])} | {row['ì¢…ëª©ëª…']} | {row['ì¢…ëª©ì½”ë“œ']} | "
                       f"{row['1ì£¼_ìˆ˜ìµë¥ ']}% | {row['12ê°œì›”_ìˆ˜ìµë¥ ']}% | "
                       f"{row['ETFì„¹í„°']} | {row['êµ­ë‚´ì™¸êµ¬ë¶„']} |\n")
            
            f.write("\n### ğŸ”» í•˜ìœ„ 10ê°œ\n\n")
            f.write("| ìˆœìœ„ | ì¢…ëª©ëª… | ì¢…ëª©ì½”ë“œ | 1ì£¼ ìˆ˜ìµë¥  | 1ë…„ ìˆ˜ìµë¥  | ETFì„¹í„° | êµ­ë‚´ì™¸ |\n")
            f.write("|------|--------|----------|-----------|-----------|---------|--------|\n")
            
            for idx, row in df_1w.tail(10).iterrows():
                f.write(f"| {int(row['1ì£¼_ìˆœìœ„'])} | {row['ì¢…ëª©ëª…']} | {row['ì¢…ëª©ì½”ë“œ']} | "
                       f"{row['1ì£¼_ìˆ˜ìµë¥ ']}% | {row['12ê°œì›”_ìˆ˜ìµë¥ ']}% | "
                       f"{row['ETFì„¹í„°']} | {row['êµ­ë‚´ì™¸êµ¬ë¶„']} |\n")
            
            # ì„¹í„°ë³„ í†µê³„
            f.write("\n---\n\n")
            f.write("## ğŸ“Š ì„¹í„°ë³„ í†µê³„\n\n")
            
            sector_stats = df.groupby('ETFì„¹í„°').agg({
                'ì¢…ëª©ì½”ë“œ': 'count'
            }).reset_index()
            sector_stats.columns = ['ì„¹í„°', 'ì¢…ëª© ìˆ˜']
            sector_stats = sector_stats.sort_values('ì¢…ëª© ìˆ˜', ascending=False)
            
            f.write("| ì„¹í„° | ì¢…ëª© ìˆ˜ |\n")
            f.write("|------|--------|\n")
            for _, row in sector_stats.iterrows():
                f.write(f"| {row['ì„¹í„°']} | {row['ì¢…ëª© ìˆ˜']} |\n")
        
        print(f"   âœ“ Markdown ì €ì¥: {filename}")
        return filename
    
    def generate_telegram_summary(self, df: pd.DataFrame) -> str:
        """
        í…”ë ˆê·¸ë¨ ìš”ì•½ ë©”ì‹œì§€ ìƒì„± (TOP 5ë§Œ)
        """
        # 1ë…„ ê¸°ì¤€ ì •ë ¬
        df_1y = df[df['12ê°œì›”_ìˆ˜ìµë¥ '] != 'ë¯¸ì¶œì‹œ'].copy()
        df_1y = df_1y.sort_values('12ê°œì›”_ìˆ˜ìµë¥ ', ascending=False)
        
        # 1ì£¼ì¼ ê¸°ì¤€ ì •ë ¬
        df_1w = df[df['1ì£¼_ìˆ˜ìµë¥ '] != 'ë¯¸ì¶œì‹œ'].copy()
        df_1w = df_1w.sort_values('1ì£¼_ìˆ˜ìµë¥ ', ascending=False)
        
        msg = f"<b>ğŸ“Š ETF ìˆ˜ìµë¥  ë¶„ì„ ì™„ë£Œ</b>\n"
        msg += f"ğŸ“… ê¸°ì¤€ì¼: {self.base_date}\n"
        msg += f"ğŸ“ˆ ë¶„ì„ ëŒ€ìƒ: {len(df)}ê°œ ETF\n\n"
        
        msg += "<b>ğŸ” 1ë…„ ìˆ˜ìµë¥  TOP 5</b>\n"
        for idx, row in df_1y.head(5).iterrows():
            msg += f"{int(row['12ê°œì›”_ìˆœìœ„'])}. {row['ì¢…ëª©ëª…']}\n"
            msg += f"   ğŸ’° 1ë…„: {row['12ê°œì›”_ìˆ˜ìµë¥ ']}% | 1ì£¼: {row['1ì£¼_ìˆ˜ìµë¥ ']}%\n"
        
        msg += f"\n<b>ğŸ” 1ì£¼ì¼ ìˆ˜ìµë¥  TOP 5</b>\n"
        for idx, row in df_1w.head(5).iterrows():
            msg += f"{int(row['1ì£¼_ìˆœìœ„'])}. {row['ì¢…ëª©ëª…']}\n"
            msg += f"   ğŸ’° 1ì£¼: {row['1ì£¼_ìˆ˜ìµë¥ ']}% | 1ë…„: {row['12ê°œì›”_ìˆ˜ìµë¥ ']}%\n"
        
        msg += f"\nâœ… ìƒì„¸ ë°ì´í„°: JSON, Excel, Markdown ì €ì¥ë¨"
        
        return msg
    
    def send_telegram_message(self, message: str):
        """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ (íŒŒì¼ ì „ì†¡ ì œê±°)"""
        if not self.telegram_token or not self.chat_id:
            print("   âš ï¸  í…”ë ˆê·¸ë¨ ì„¤ì • ì—†ìŒ - ì „ì†¡ ìŠ¤í‚µ")
            return
        
        try:
            url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
            data = {
                "chat_id": self.chat_id,
                "text": message,
                "parse_mode": "HTML"
            }
            response = requests.post(url, data=data)
            
            if response.status_code == 200:
                print("   âœ“ í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ")
            else:
                print(f"   âœ— í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            
        except Exception as e:
            print(f"   âœ— í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def run(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰ (GitHub Actions íŒ¨í„´)"""
        # 1. APIë¡œ ë°ì´í„° ìˆ˜ì§‘
        df = self.analyze_etfs()
        
        if df is None:
            return None
        
        # 2. ë°ì´í„° ì €ì¥ (JSON, Excel, Markdown)
        print("\nğŸ“ ë°ì´í„° ì €ì¥ ì¤‘...")
        json_file = self.save_to_json(df)
        excel_file = self.save_to_excel(df)
        md_file = self.save_to_markdown(df)
        
        # 3. Git commitì€ workflowì—ì„œ ìˆ˜í–‰
        print("\nğŸ“¤ í…”ë ˆê·¸ë¨ ìš”ì•½ ì „ì†¡ ì¤‘...")
        summary = self.generate_telegram_summary(df)
        self.send_telegram_message(summary)
        
        print("\n" + "=" * 60)
        print("âœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼:")
        print(f"   - {json_file}")
        print(f"   - {excel_file}")
        print(f"   - {md_file}")
        print("=" * 60)
        
        return df


if __name__ == "__main__":
    analyzer = ETFPerformanceAnalyzer()
    result_df = analyzer.run()
    
    if result_df is not None:
        print("\nğŸ“‹ ê²°ê³¼ ìƒ˜í”Œ:")
        print(result_df.head(10))
